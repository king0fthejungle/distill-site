{
  "articles": [
    {
      "path": "index.html",
      "title": "Brady Falor's Porfolio",
      "author": [],
      "contents": "\nAbout Me\nHi, I’m Brady Falor. I’m passionate about data science, machine learning, and statistical analysis.\nFind more about me\nLinkedIn\nKaggle\nGitHub\n\n\n\n",
      "last_modified": "2024-08-04T16:27:37-04:00"
    },
    {
      "path": "logistic.html",
      "title": "Logistic Regression",
      "description": "Explaining and using Logistic Regression ",
      "author": [],
      "contents": "\nIntroduction:\nThis website is built using distill and R, and as you progress you will notice bit of R code that help me to fit and assess statistical models to solve the overall problem.\nChurn is the rate at which clients or customers stop doing business with a company over time. A common problem in data science is to predict churn.\nThere are two states a customer can be in, if they are still doing business they have not churned (Churn = FALSE or 0), if they are no longer doing business then they have churned (Churn = TRUE or 1).\nApplying the appropriate generalized linear model\nGiven we have a data set that includes other characteristics (independent variables, X) about each customer and whether or not they have churned, we can model this relationship using logistic regression as so:\nThe logistic regression model predicts the probability \\(P(Y=1)\\) of the dependent variable \\(Churn\\) being 1 (or True), given the independent variables \\(X_1, X_2, \\ldots, X_n\\). The equation is:\n\\[\nP(Churn=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_n X_n)}}\n\\]\nWhere:\n- \\(P(Y=1|X)\\) is the probability of \\(Y\\) being 1 given \\(X\\).\n- \\(\\beta_0\\) is the intercept.\n- \\(\\beta_1, \\beta_2, \\ldots, \\beta_n\\) are the coefficients of the independent variables \\(X_1, X_2, \\ldots, X_n\\).\n- \\(e\\) is the base of the natural logarithm.\nThe logistic function (also called the sigmoid function) is used to map the predicted values to probabilities.\n\\[\nP(Churn=1|X) = \\sigma(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_n X_n)\n\\]\nWhere \\(\\sigma(z)\\) is the sigmoid function defined as:\n\\[\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\]\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# Model evaluation\nlibrary(dplyr)\n\n\nData Source\n\n\ntrain_df <- read_csv(\"~/STA 631/distill-site/data/churn-bigml-80.csv\")\ntest_df <- read_csv(\"~/STA 631/distill-site/data/churn-bigml-20.csv\")\n\n\n\n\nglimpse(train_df)\n\nRows: 2,666\nColumns: 20\n$ State                    [3m[38;5;246m<chr>[39m[23m \"KS\", \"OH\", \"NJ\", \"OH\", \"OK\", \"AL\",…\n$ `Account length`         [3m[38;5;246m<dbl>[39m[23m 128, 107, 137, 84, 75, 118, 121, 14…\n$ `Area code`              [3m[38;5;246m<dbl>[39m[23m 415, 415, 415, 408, 415, 510, 510, …\n$ `International plan`     [3m[38;5;246m<chr>[39m[23m \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Ye…\n$ `Voice mail plan`        [3m[38;5;246m<chr>[39m[23m \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"No…\n$ `Number vmail messages`  [3m[38;5;246m<dbl>[39m[23m 25, 26, 0, 0, 0, 0, 24, 0, 37, 0, 0…\n$ `Total day minutes`      [3m[38;5;246m<dbl>[39m[23m 265.1, 161.6, 243.4, 299.4, 166.7, …\n$ `Total day calls`        [3m[38;5;246m<dbl>[39m[23m 110, 123, 114, 71, 113, 98, 88, 79,…\n$ `Total day charge`       [3m[38;5;246m<dbl>[39m[23m 45.07, 27.47, 41.38, 50.90, 28.34, …\n$ `Total eve minutes`      [3m[38;5;246m<dbl>[39m[23m 197.4, 195.5, 121.2, 61.9, 148.3, 2…\n$ `Total eve calls`        [3m[38;5;246m<dbl>[39m[23m 99, 103, 110, 88, 122, 101, 108, 94…\n$ `Total eve charge`       [3m[38;5;246m<dbl>[39m[23m 16.78, 16.62, 10.30, 5.26, 12.61, 1…\n$ `Total night minutes`    [3m[38;5;246m<dbl>[39m[23m 244.7, 254.4, 162.6, 196.9, 186.9, …\n$ `Total night calls`      [3m[38;5;246m<dbl>[39m[23m 91, 103, 104, 89, 121, 118, 118, 96…\n$ `Total night charge`     [3m[38;5;246m<dbl>[39m[23m 11.01, 11.45, 7.32, 8.86, 8.41, 9.1…\n$ `Total intl minutes`     [3m[38;5;246m<dbl>[39m[23m 10.0, 13.7, 12.2, 6.6, 10.1, 6.3, 7…\n$ `Total intl calls`       [3m[38;5;246m<dbl>[39m[23m 3, 3, 5, 7, 3, 6, 7, 6, 5, 5, 2, 5,…\n$ `Total intl charge`      [3m[38;5;246m<dbl>[39m[23m 2.70, 3.70, 3.29, 1.78, 2.73, 1.70,…\n$ `Customer service calls` [3m[38;5;246m<dbl>[39m[23m 1, 1, 0, 2, 3, 0, 3, 0, 0, 0, 1, 3,…\n$ Churn                    [3m[38;5;246m<lgl>[39m[23m FALSE, FALSE, FALSE, FALSE, FALSE, …\n\n\n\n# removing white space from column names\nnames(train_df) <- gsub(\" \", \"_\", names(train_df))\nnames(test_df) <- gsub(\" \", \"_\", names(test_df))\n\n# Print modified column names\nprint(colnames(train_df))\n\n [1] \"State\"                  \"Account_length\"        \n [3] \"Area_code\"              \"International_plan\"    \n [5] \"Voice_mail_plan\"        \"Number_vmail_messages\" \n [7] \"Total_day_minutes\"      \"Total_day_calls\"       \n [9] \"Total_day_charge\"       \"Total_eve_minutes\"     \n[11] \"Total_eve_calls\"        \"Total_eve_charge\"      \n[13] \"Total_night_minutes\"    \"Total_night_calls\"     \n[15] \"Total_night_charge\"     \"Total_intl_minutes\"    \n[17] \"Total_intl_calls\"       \"Total_intl_charge\"     \n[19] \"Customer_service_calls\" \"Churn\"                 \n\n\n\ntable(train_df$Churn)\n\n\nFALSE  TRUE \n 2278   388 \n\n\n\nlibrary(naniar)\n\nvis_miss(train_df)\n\n\n\nThere is no missing data! Excellent.\nConduct Model Selection from a set of candidate models\nThe goal of this section is to perform subset selection where we identify a subset of predictors that are related to the response variable.\nFirst lets perform preprocessing, lets use a recipe to one-hot encode our variables:\n\n\ntrain_df <- train_df |>\n  mutate(Churn = if_else(Churn, 1, 0))\n\n\nrec <- recipe(Churn ~ ., data = train_df) |>\n  step_dummy(all_nominal_predictors(), one_hot = FALSE) |> # Dummy encode categorical variables\n  prep()\n\n# Apply the recipe to the data\ntrain_processed <- bake(rec, new_data = train_df)\n\n\nTraining a Model\nNow lets train a model with everything to see how it performs:\n\n\n# Create the logistic regression model using glm\nmodel <- glm(Churn ~ ., data = train_processed, family = binomial())\nsummary(model)\n\n\nCall:\nglm(formula = Churn ~ ., family = binomial(), data = train_processed)\n\nCoefficients:\n                         Estimate Std. Error z value Pr(>|z|)    \n(Intercept)            -8.920e+00  1.260e+00  -7.079 1.45e-12 ***\nAccount_length          1.482e-03  1.630e-03   0.909  0.36343    \nArea_code              -3.446e-04  1.532e-03  -0.225  0.82202    \nNumber_vmail_messages   4.076e-02  2.143e-02   1.902  0.05721 .  \nTotal_day_minutes      -3.491e-01  3.826e+00  -0.091  0.92729    \nTotal_day_calls         3.608e-03  3.246e-03   1.111  0.26643    \nTotal_day_charge        2.132e+00  2.251e+01   0.095  0.92455    \nTotal_eve_minutes       1.419e+00  1.921e+00   0.738  0.46029    \nTotal_eve_calls        -1.615e-03  3.220e-03  -0.501  0.61609    \nTotal_eve_charge       -1.662e+01  2.260e+01  -0.735  0.46223    \nTotal_night_minutes     4.749e-04  1.023e+00   0.000  0.99963    \nTotal_night_calls       1.735e-03  3.294e-03   0.527  0.59839    \nTotal_night_charge      5.718e-02  2.272e+01   0.003  0.99799    \nTotal_intl_minutes     -2.985e+00  6.178e+00  -0.483  0.62895    \nTotal_intl_calls       -1.228e-01  3.005e-02  -4.086 4.38e-05 ***\nTotal_intl_charge       1.141e+01  2.288e+01   0.499  0.61795    \nCustomer_service_calls  5.463e-01  4.662e-02  11.718  < 2e-16 ***\nState_AL                2.075e-01  7.925e-01   0.262  0.79346    \nState_AR                8.758e-01  7.711e-01   1.136  0.25607    \nState_AZ                1.406e-01  9.246e-01   0.152  0.87916    \nState_CA                1.309e+00  8.860e-01   1.477  0.13969    \nState_CO                3.176e-01  7.994e-01   0.397  0.69114    \nState_CT                1.150e+00  7.500e-01   1.533  0.12524    \nState_DC                7.592e-01  8.254e-01   0.920  0.35770    \nState_DE                6.462e-01  7.753e-01   0.833  0.40463    \nState_FL                5.189e-01  7.931e-01   0.654  0.51291    \nState_GA                7.058e-01  7.902e-01   0.893  0.37175    \nState_HI               -7.328e-01  1.002e+00  -0.731  0.46457    \nState_IA                3.493e-01  9.146e-01   0.382  0.70252    \nState_ID                3.175e-01  8.344e-01   0.381  0.70355    \nState_IL               -4.100e-01  8.949e-01  -0.458  0.64683    \nState_IN                2.688e-01  8.043e-01   0.334  0.73824    \nState_KS                9.024e-01  7.661e-01   1.178  0.23883    \nState_KY                5.636e-01  8.182e-01   0.689  0.49096    \nState_LA                5.682e-01  9.068e-01   0.627  0.53091    \nState_MA                1.069e+00  7.853e-01   1.361  0.17346    \nState_MD                9.575e-01  7.461e-01   1.283  0.19937    \nState_ME                1.375e+00  7.587e-01   1.813  0.06987 .  \nState_MI                1.285e+00  7.462e-01   1.722  0.08506 .  \nState_MN                1.175e+00  7.426e-01   1.583  0.11353    \nState_MO                3.961e-01  8.306e-01   0.477  0.63344    \nState_MS                1.505e+00  7.654e-01   1.967  0.04920 *  \nState_MT                1.645e+00  7.562e-01   2.176  0.02957 *  \nState_NC                2.904e-01  7.996e-01   0.363  0.71650    \nState_ND                2.940e-03  8.741e-01   0.003  0.99732    \nState_NE                2.949e-01  8.536e-01   0.345  0.72973    \nState_NH                1.305e+00  7.888e-01   1.654  0.09811 .  \nState_NJ                1.398e+00  7.471e-01   1.871  0.06134 .  \nState_NM                3.212e-01  8.655e-01   0.371  0.71052    \nState_NV                1.040e+00  7.450e-01   1.395  0.16289    \nState_NY                1.111e+00  7.467e-01   1.488  0.13671    \nState_OH                7.216e-01  7.650e-01   0.943  0.34559    \nState_OK                5.418e-01  7.982e-01   0.679  0.49728    \nState_OR                3.802e-01  7.912e-01   0.481  0.63080    \nState_PA                1.244e+00  8.055e-01   1.544  0.12260    \nState_RI               -9.942e-01  9.569e-01  -1.039  0.29882    \nState_SC                1.726e+00  7.675e-01   2.249  0.02451 *  \nState_SD                4.039e-01  8.078e-01   0.500  0.61703    \nState_TN                3.497e-01  8.477e-01   0.412  0.67998    \nState_TX                1.809e+00  7.353e-01   2.461  0.01386 *  \nState_UT                9.522e-01  7.754e-01   1.228  0.21945    \nState_VA               -6.646e-01  8.765e-01  -0.758  0.44833    \nState_VT               -2.364e-01  8.448e-01  -0.280  0.77962    \nState_WA                1.326e+00  7.692e-01   1.724  0.08473 .  \nState_WI               -1.862e-01  8.740e-01  -0.213  0.83128    \nState_WV                2.495e-01  7.771e-01   0.321  0.74819    \nState_WY                2.085e-01  7.812e-01   0.267  0.78952    \nInternational_plan_Yes  2.278e+00  1.704e-01  13.373  < 2e-16 ***\nVoice_mail_plan_Yes    -2.159e+00  6.811e-01  -3.170  0.00152 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2212.2  on 2665  degrees of freedom\nResidual deviance: 1641.2  on 2597  degrees of freedom\nAIC: 1779.2\n\nNumber of Fisher Scoring iterations: 6\n\nSubset Selection\nOur model has an AIC of 1779.2, lets now see if we can improve it with a subset selection algorithm:\nAlthough we have a binary classification problem where we would like to perform logisitic regression, we can still use regsubsets from the leaps package to help use understand what subsets would work best for linear regression models.\nBecause we have p = 20 predictors, exhaustive best subset selection is not reasonable.\n\n\nlibrary(leaps)\n\nregfit <- regsubsets(Churn ~ ., data = train_processed, nvmax = 50, method = \"backward\")\nsummary_reg_fit <- summary(regfit)\n\n\nNow that we have our 50 candidate models, lets train logistic regression models on each subset that regsubsets built for us using linear regression models, and select the model that results in the lowest AIC value.\n\n\nbest_models <- as.data.frame(summary_reg_fit$which)\nbest_models <- best_models[, -1]\n\n# Init Empty AIC Vector\naic_values <- numeric(nrow(best_models))\n\nfor (i in 1:nrow(best_models)) {\n  current_model <- as.logical(best_models[i, ]) # Gives us a binary vector\n\n  selected_predictors <- names(best_models)[current_model]  # Only select the columns from the candidate model\n  \n  # Train the logistic regression model\n  formula <- as.formula(paste(\"Churn ~\", paste(selected_predictors, collapse = \" + \")))\n  fit <- glm(formula, data = train_processed, family = binomial)\n  \n  # store the AIC of the model\n  aic_values[i] <- AIC(fit)\n}\n\n# select the model with the lowest AIC\nbest_model_index <- which.min(aic_values)\nbest_model <- as.logical(best_models[best_model_index, ])\n\n# Re-train a logisitc regression model using the best subset \nselected_best_predictors <- names(best_models)[best_model]\nbest_formula <- as.formula(paste(\"Churn ~\", paste(selected_best_predictors, collapse = \" + \")))\nbest_fit <- glm(best_formula, data = train_processed, family = binomial)\n\nsummary(best_fit)\n\n\nCall:\nglm(formula = best_formula, family = binomial, data = train_processed)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)            -8.684033   0.697692 -12.447  < 2e-16 ***\nAccount_length          0.001368   0.001613   0.848 0.396437    \nNumber_vmail_messages   0.038958   0.021095   1.847 0.064781 .  \nTotal_day_calls         0.003490   0.003191   1.094 0.274041    \nTotal_day_charge        0.077284   0.007382  10.469  < 2e-16 ***\nTotal_eve_minutes       0.006082   0.001305   4.659 3.18e-06 ***\nTotal_night_charge      0.069230   0.028505   2.429 0.015153 *  \nTotal_intl_calls       -0.121521   0.029635  -4.101 4.12e-05 ***\nTotal_intl_charge       0.359486   0.087630   4.102 4.09e-05 ***\nCustomer_service_calls  0.544496   0.046068  11.819  < 2e-16 ***\nState_AR                0.533597   0.425092   1.255 0.209388    \nState_CA                0.984126   0.600453   1.639 0.101219    \nState_CT                0.820130   0.384905   2.131 0.033111 *  \nState_HI               -1.042918   0.765884  -1.362 0.173287    \nState_KS                0.575603   0.414311   1.389 0.164740    \nState_MA                0.735973   0.446823   1.647 0.099532 .  \nState_MD                0.610034   0.378263   1.613 0.106804    \nState_ME                1.019690   0.397382   2.566 0.010287 *  \nState_MI                0.949521   0.377625   2.514 0.011922 *  \nState_MN                0.827351   0.370660   2.232 0.025608 *  \nState_MS                1.150270   0.413325   2.783 0.005386 ** \nState_MT                1.296031   0.397695   3.259 0.001119 ** \nState_NH                0.972391   0.453971   2.142 0.032196 *  \nState_NJ                1.070657   0.376960   2.840 0.004508 ** \nState_NV                0.721948   0.375428   1.923 0.054480 .  \nState_NY                0.774550   0.378783   2.045 0.040871 *  \nState_PA                0.920228   0.484791   1.898 0.057671 .  \nState_RI               -1.297771   0.701948  -1.849 0.064485 .  \nState_SC                1.407910   0.413761   3.403 0.000667 ***\nState_TX                1.465708   0.354614   4.133 3.58e-05 ***\nState_UT                0.603891   0.433081   1.394 0.163195    \nState_VA               -1.028869   0.594978  -1.729 0.083763 .  \nState_WA                1.007015   0.422293   2.385 0.017096 *  \nInternational_plan_Yes  2.233803   0.166218  13.439  < 2e-16 ***\nVoice_mail_plan_Yes    -2.079661   0.669528  -3.106 0.001895 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2212.2  on 2665  degrees of freedom\nResidual deviance: 1650.8  on 2631  degrees of freedom\nAIC: 1720.8\n\nNumber of Fisher Scoring iterations: 6\n\nWith a simple subset selection we were able to reduce the AIC from 1779.2 to 1725.7, indicating that our model selection helped us to find a better model along with reducing the data needed to make predictions.\nCommunicating Results to a general audience\nCross Validation\nLets now do K-Fold cross validation, in this case K=10. :\n\n\nlibrary(boot)\n\ncv_error <- rep(0,10)\n\nfor (i in 1:10){\n  logistic_model <- glm(best_formula, data = train_processed, family = binomial())\n  cv_error[i] <- cv.glm(train_processed, logistic_model, K = 10)$delta[1]\n}\n\ncv_error\n\n [1] 0.09735582 0.09758029 0.09851404 0.09806621 0.09796019 0.09812609\n [7] 0.09807105 0.09729530 0.09834454 0.09754029\n\nOur estimated test errors for each fold are all very close in value, which tells us that this model will generalize should a test set not be available, luckily we have a test set available…\nProcessing Test\n\n\ntable(test_df$Churn)\n\n\nFALSE  TRUE \n  572    95 \n\n\n\ntest_df <- test_df |>\n  mutate(Churn = if_else(Churn, 1, 0))\n\ntest_processed <- bake(rec, new_data = test_df)\n\n\nMaking Predictions\n\n\n# Make predictions on the test data (excluding the Churn column)\npredictions <- predict(best_fit, newdata = dplyr::select(test_processed, -Churn), type = \"response\")\n\n# Add predictions and actual Churn back to the test data frame for evaluation\ntest_df <- test_df |>\n  mutate(predicted_Churn = predictions)\n\n# If a prediction has a probability greater than 0.5 we will assign it to 1, otherwise 0. \ntest_df <- test_df |>\n  mutate(predicted_Churn_binary = if_else(predicted_Churn > 0.5, 1, 0))\n\n\nEvaluating Predictions\n\n\n# Confusion Matrix\nTP <- sum(test_df$predicted_Churn_binary == 1 & test_df$Churn == 1)\nFP <- sum(test_df$predicted_Churn_binary == 1 & test_df$Churn == 0)\nTN <- sum(test_df$predicted_Churn_binary == 0 & test_df$Churn == 0)\nFN <- sum(test_df$predicted_Churn_binary == 0 & test_df$Churn == 1)\n\nprint(paste(\"True Positives (TP):\", TP))\n\n[1] \"True Positives (TP): 25\"\n\nprint(paste(\"False Positives (FP):\", FP))\n\n[1] \"False Positives (FP): 19\"\n\nprint(paste(\"True Negatives (TN):\", TN))\n\n[1] \"True Negatives (TN): 553\"\n\nprint(paste(\"False Negatives (FN):\", FN))\n\n[1] \"False Negatives (FN): 70\"\n\n# Calculate Precision, Recall, and F1 Score\nprecision <- TP / (TP + FP)\nrecall <- TP / (TP + FN)\nf1_score <- 2 * ((precision * recall) / (precision + recall))\n\n# Print Precision, Recall, and F1 Score\nprint(paste(\"Precision:\", precision))\n\n[1] \"Precision: 0.568181818181818\"\n\nprint(paste(\"Recall:\", recall))\n\n[1] \"Recall: 0.263157894736842\"\n\nprint(paste(\"F1 Score:\", f1_score))\n\n[1] \"F1 Score: 0.359712230215827\"\n\nResults\nWe aimed to predict Churn using a telecom dataset using a Logistic Regression model. This was a binary classification where we attempted to train a model to understand the relationships between 20 possible variables and churn to effectively predict churn.\nA subset selection was done in order to identify which variables had the most predictive power and which ones could be removed from the available predictors. Our model that having an international plan was the most significant predictor that indicated a customer will churn(having the highest positive coefficient), while having a voicemail plan was the most significant predictors that indicated a customer will not churn (having the highest negative coefficient).\nThe best logistic regression model produced was evaluated against the test set and resulted in an F1-Score of 0.359, which is sub-optimal and perhaps not yet ready for any effective use. However, we did learn that perhaps marketing and including voicemail plans could perhaps lead to a lower churn rate.\n\n\n\n",
      "last_modified": "2024-08-04T16:27:44-04:00"
    },
    {
      "path": "STA631Reflection.html",
      "title": "Learning Objective Reflections",
      "description": "Links to demonstrations and reflections",
      "author": [],
      "contents": "\nObjective 1: Describe probability as a foundation of statistical modeling, including inference and maximum likelihood estimation\nWithin the Statistical Learning tab you will find a page that explains probability using the idea of a coin flip, explains probability distribution using the simulation of dice rolls, makes an inference for a task using a confidence intervals, and lastly shares how we can use the concept of maximum likelihood estimation to make a prediction. First, a primer on probability is given which effectively clears the audience’s palette to make way for the secure foundation for statistical modeling. Second the central limit theorem is explained via a simulation of many dice rolls to lay the cement for the foundation. Finally, the cement hardens by including the concepts of inference and maximum likelihood estimation. As a result this objective is sufficiently met.\nObjective 2: Determine and apply the appropriate generalized linear model for a specific data context\nWithin the Logistic Regression tab there is a section titled “Applying the appropriate generalized linear model” where a problem is identified and the appropriate generalized linear model is applied for the specific data given. The first section explores a data solution to the common problem of customer churn. It identifies that the outcome we’d like to learn is of a binary nature, and thus logistic regression the appropriate generalized linear model (GLM) to use. Should the problem have been to predict a customer’s count of calls made in a time-frame then a Poisson regression model would be appropriate, or if the problem was to predict the income of each customer based on their habits than a multiple linear regression model would be appropriate. However since the data was in the context of making a binary prediction of Churn = True or Churn = False, the logistic regression model is appropriate. Once the correct GLM was identified it was then explained given the statistical data context.\nObjective 3: Conduct model selection for a set of candidate models\nWithin the Logistic Regression tab there is a section titled “Conduct Model Selection from a set of candidate models” where subset selection is performed to improve upon a logistic regression model. Within this section an appropriate model selection technique for the given data was chosen, it was determined that best subset selection was not appropriate given that the number of predictors was large it would not be computationally efficient to perform best-subset selection. Instead, backward selection was used to remove predictors that had a negligible influence on the customer churn, in order to create a more potent and efficient data set for the logistic regression model to learn from. From our backward selection I obtained 50 different models with different possible subsets of predictors for a LINEAR regression problem, of these 50 different models I used the subsets to generate a list of 50 different LOGISITIC regression models to fit the data context, and of these 50 models the model with the lowest AIC value was selected.\nObjective 4: Communicate the results of statistical models to a general audience\nWithin the Logistic Regression tab there is a section titled “Communicating Results to a general audience” where the best model is evaluated against the test split, cross validated, and a summary of the model results is shared. First cross validation is performed to ensure that our model performs similarly across different folds of the training set. Secondly, I ensure that the test data is processed in the same manner the training data was (one-hot encoding), and that the correct subset selection was made from the test_set before evaluating the model with it. When evaluating I chose appropriate metrics to understand how well our model was performing; recall, precision, and F1 score. I then summarized the various results in a manner with which someone without statistical training could understand, share the predictors that had the coefficients of great magnitude and interpreted whether or not the current model should be used, thus I appropriately met the objective of communicating the results of a statistical model to a general audience.\nObjective 5: Use programming software (i.e., R) to fit and assess statistical models\nThe entirety of the Logistic regression section demonstrates this learning objective. Within this page a logistic regression model is fit to a dataset of 20 predictors to classify a record as Churn or not Churn. The model is then assessed to be generalizable by performing 10-fold Cross Validation against the training split. Then the model is further assessed by by performing prediction using the test set, and calculating various metrics. All of this was done using the software R in Posit Cloud, knitting and rendering a distill website to display this information, and deploying it to GitHub pages. As a result, the objective to use R to fit and assess statistical models is appropriately met.\nParticipation in Course Community\nI attended all classes with my full attention, and gave my best effort to build a clear understanding of statistical modeling. When a general question was posed to the audience by the professor I was often one of the few students who responded with an idea or answer. I will concede that given the course was online, and I was participating in a full-time internship throughout the full duration of the course, that my goals of connecting with my classmates were not quite achieved. However, I did manage to reach out to some classmates and attempt to answer some questions I received about where to find specific directions needed for some assignments, and I did connect with a few classmates on Linkedin. I wasn’t able to keep pace with the Data Feminism book asynchronous discussions as the semester paced on, but I did pace with some and I have been reading Data Feminism and hope to complete it soon. During class periods where breakout working sessions were formed I did take it upon myself to lead the group in which I was placed and encouraged my fellow group members to contribute to the conversation. For an online course, i do feel that while my ideal contributions were not met, I still made significant contribution towards the general success of the class and my individual learning.\n\n\n\n",
      "last_modified": "2024-08-04T16:27:45-04:00"
    },
    {
      "path": "statlearn.html",
      "title": "Statistical Learning",
      "description": "An explanation of how probability lays the foundation for statistical learning",
      "author": [],
      "contents": "\nDescribe probability as a foundation of statistical modeling, including inference and maximum likelihood estimation\nA Primer on Probability using a coin flip\nThe probability of an event is a measurement of how likely it is to occur, and ranges from 0 to 1.\nA probability of 0 means the event will not occur, and a probability of 1 means the event will surely occur.\nTake a coin flip - the probability of flipping heads is 0.5, this is because out of two possible outcomes heads is one of them: 1/2 = 0.5. Each outcome then has a 50% chance of happening. However a small sample size we may not equal results between heads and tails:\n\n\n\nThough if we repeat this coin flip many more times we will begin to see that the frequency of our observations will match the expected probability of 0.5:\n\n\n\nA coin flip results in a binary outcome where there are only two possible results: heads or tails. While we can be certain it would be impossible to accurately predict these outcome of each individual flip, we can be confident about predicting the aggregate results of many flips. For example if we flip a coin 100,000 times we can easily approximate that about 50,000 will be heads, and about 50,000 will be tails. This an exmaple of the concept commonly shared as “regression to the mean”.\nProbability Distributions\nLets simulate rolling 6-sided dice 10 times, each time we will calculate the sum of rolling both dice and store this sum away. Then we will count the relative frequencies of each sum and visualize them with a histogram.\n\n\n\nHere we can be assured that the results of the dice rolls are quite random, however what if we repeat this experiment but instead roll the dice 10,000 times?\n\n\n\nNow we see that the dice rolls are in-fact not random and there is a discernable pattern, called the “normal distribution”. This normal distribution is result of the rules outlined in the Central Limit Theorem. The Central Limit Theorem states that regardless of the original distribution of a random variable (result of a dice roll) the distribution of the sample mean will approach a normal distribution as the sample size becomes large.\nStatistical Inference\nNow lets assume you are tasked with predicting the sum of a the roll of two dice. After viewing the graph, we can expect that because 7 has the greatest relative frequency, it has the highest probability of occurring.\nWe can perform a t-test to generate a 95% confidence interval on our sets of sums to confirm this:\n\n[1] \"95% Confidence Interval for the Mean of Dice Roll Sums: 5.61 to 9.39\"\n\nSince 7 is the only whole-number that falls within the 95% confidence interval range, we can make a statistical inference that 7 is the prediction that gives use the best odds of being correct. This is the foundation for which statistical models are built upon.\nMaximum Likelihood Estimation\nThe concept of Maximum Likelihood is an idea that the parameters of a statistical model can be estimated. Using the probability density of each data point (in our case a roll of two dice), we can measure how likely it is to be observed with various parameter values (in our case we can focus on the mean).\nWe are confident that our data follows a normal distribution, thus we can simply take the sample mean, and sample standard deviation to maximize the likelihood functions (which are outside the scope of this document).\n\n[1] \"MLE Estimate of Mean: 7.5\"\n[1] \"MLE Estimate of Standard Deviation: 2.64\"\n\nGiven our maximum likelihood estimate for the mean is about 7, we can again confirm that a prediction of 7 would be prudent. Now we have a simple understand of how probability lays the foundation for statistical modeling, and a more complex example using logistic regression can be found on the Logistic page of this site.\n\n\n\n",
      "last_modified": "2024-08-04T16:27:46-04:00"
    }
  ],
  "collections": []
}
